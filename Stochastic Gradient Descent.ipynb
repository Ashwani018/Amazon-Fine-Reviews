{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of SGDRegressor from Scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the Boston data set from the Sklearn Library :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data from the boston dataset:\n",
    "data = boston.data #featured data\n",
    "target = boston.target #variable values\n",
    "\n",
    "\n",
    "boston_df = pd.DataFrame(data)\n",
    "X = boston_df\n",
    "y = target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data (mean=0, std=1) using training data\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "standardized_X = X_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the SGD Model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below function will compute the cost for each point:\n",
    "def  cal_cost(theta,X,y,m):\n",
    "    #m = len(y)\n",
    "    \n",
    "    predictions = X.dot(theta)\n",
    "    \n",
    "    cost = (1/2*506) * np.sum(np.square(predictions-y))\n",
    "    \n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below method will compute the optimal weights and cost :\n",
    "def stochastic_gradient_descent(X,y,theta,learning_rate=0.01,iterations=10):\n",
    "  \n",
    "    m = len(y) #length of the data set\n",
    "    cost_value = np.zeros(iterations)\n",
    "    \n",
    "    \n",
    "    for it in range(iterations):\n",
    "        cost =0.0\n",
    "        \n",
    "        for i in range(m):\n",
    "            rand_ind = np.random.randint(0,m)\n",
    "            X_i = X[rand_ind,:].reshape(1,X.shape[1])\n",
    "            y_i = y[rand_ind].reshape(1,1)\n",
    "            prediction = np.dot(X_i,theta)\n",
    "            \n",
    "            theta = theta -(2/m)*learning_rate*( X_i.T.dot((prediction - y_i)))\n",
    "            cost += cal_cost(theta,X_i,y_i,m)\n",
    "            \n",
    "            \n",
    "        cost_value[it]  = cost\n",
    "        \n",
    "    return theta, cost_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr =0.2 #learning_rate\n",
    "n_iter = 100 #no. of iterations\n",
    "\n",
    "theta = np.random.randn(14,1)\n",
    "\n",
    "X_b = np.c_[np.ones((len(standardized_X),1)),standardized_X] #adding the bias weight's features\n",
    "\n",
    "theta_updated,cost_history = stochastic_gradient_descent(X_b,y,theta,lr,n_iter) # calling the sgd_function\n",
    "\n",
    "print(cost_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept Term(bias term) :  22.555\n",
      "\n",
      "****************************************************************************************************\n",
      "Predicted Weights(without bias term :)\n",
      "[[-0.9638304 ]\n",
      " [ 0.9149475 ]\n",
      " [-0.01600848]\n",
      " [ 0.56743312]\n",
      " [-2.08737184]\n",
      " [ 2.80564371]\n",
      " [ 0.1813708 ]\n",
      " [-3.09703528]\n",
      " [ 2.45499635]\n",
      " [-1.75823064]\n",
      " [-2.11377119]\n",
      " [ 0.80181488]\n",
      " [-3.9207029 ]]\n"
     ]
    }
   ],
   "source": [
    "print('Intercept Term(bias term) :  {:0.3f}\\n'.format(theta_updated[0][0]))\n",
    "\n",
    "print('*'*100)\n",
    "print('Predicted Weights(without bias term :)')\n",
    "weight_vector = theta_updated[1:]\n",
    "print(weight_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error using the predicted weights : 21.991174425443887\n"
     ]
    }
   ],
   "source": [
    "y_predicted = X_b.dot(theta_updated)\n",
    "\n",
    "y_predicted = y_predicted.ravel()\n",
    "error = y -y_predicted\n",
    "mse_sgd = np.mean(error**2)\n",
    "print('Mean Squared Error using the predicted weights :' , mse_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn's SGDRegressor :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', max_iter=None, n_iter=100, penalty=None,\n",
       "       power_t=0.25, random_state=None, shuffle=True, tol=None, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Computing the intercept and weight coffecients using the sklearn library:\n",
    "\n",
    "lm = SGDRegressor(n_iter = 100 , penalty=None , loss='squared_loss' )\n",
    "lm.fit(standardized_X , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept term : [22.53564532]\n"
     ]
    }
   ],
   "source": [
    "#Intercept Calculation:\n",
    "print('Intercept term :' , lm.intercept_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight vector :\n",
      " [[-0.91026934]\n",
      " [ 1.05890443]\n",
      " [ 0.11355234]\n",
      " [ 0.67833332]\n",
      " [-2.04260332]\n",
      " [ 2.65719259]\n",
      " [ 0.02343965]\n",
      " [-3.12238977]\n",
      " [ 2.55149977]\n",
      " [-1.9320931 ]\n",
      " [-2.05428794]\n",
      " [ 0.84663064]\n",
      " [-3.73052709]]\n"
     ]
    }
   ],
   "source": [
    "#Coffecient Calculation :\n",
    "print('Weight vector :\\n' , lm.coef_.reshape(-1 , 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting the target values for standardised data :\n",
    "\n",
    "y_predict = lm.predict(standardized_X)\n",
    "y_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 21.90851533259455\n"
     ]
    }
   ],
   "source": [
    "#mean square error\n",
    "\n",
    "mse_sklearn = np.mean((y - y_predict)**2)\n",
    "print('MSE:' , mse_sklearn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing our SGD model to Sklearn's  SGDRegressor :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias Term (Intercept Term) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.55490109, 22.53564532])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept = np.hstack([theta_updated[0][0] , lm.intercept_])\n",
    "intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Vector :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.9638304 , -0.91026934],\n",
       "       [ 0.9149475 ,  1.05890443],\n",
       "       [-0.01600848,  0.11355234],\n",
       "       [ 0.56743312,  0.67833332],\n",
       "       [-2.08737184, -2.04260332],\n",
       "       [ 2.80564371,  2.65719259],\n",
       "       [ 0.1813708 ,  0.02343965],\n",
       "       [-3.09703528, -3.12238977],\n",
       "       [ 2.45499635,  2.55149977],\n",
       "       [-1.75823064, -1.9320931 ],\n",
       "       [-2.11377119, -2.05428794],\n",
       "       [ 0.80181488,  0.84663064],\n",
       "       [-3.9207029 , -3.73052709]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = np.hstack([weight_vector , lm.coef_.reshape(-1 ,1)])\n",
    "weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# MSE Comparison: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.99117443, 21.90851533])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_array = np.hstack([mse_sgd , mse_sklearn])\n",
    "mse_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## CONCLUSION:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) We got same approximately same values for the weight vector , intercept term and Mean Squared Error values in case of SGD from scratch and Sklearn SGD model.\n",
    "\n",
    "### 2) So our model is working fine with learning rate(eat0) = 0.2 and n_iter = 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
